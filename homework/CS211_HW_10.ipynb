{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS211: Data Privacy\n",
    "## Homework 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def gaussian_mech_vec(vec, sensitivity, epsilon, delta):\n",
    "    return [v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "            for v in vec]\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "# adult = pd.read_csv('https://github.com/jnear/cs211-data-privacy/raw/master/homework/adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "url_x = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_x.npy'\n",
    "url_y = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_y.npy'\n",
    "\n",
    "with urllib.request.urlopen(url_x) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "X = np.load(f)\n",
    "\n",
    "with urllib.request.urlopen(url_y) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "training_size = int(X.shape[0] * 0.8)\n",
    "\n",
    "X_train = X[:training_size]\n",
    "X_test = X[training_size:]\n",
    "\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "print('Train and test set sizes:', len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss function measures how good our model is. The training goal is to minimize the loss.\n",
    "# This is the logistic loss function.\n",
    "def loss(theta, xi, yi):\n",
    "    exponent = - yi * (xi.dot(theta))\n",
    "    return np.log(1 + np.exp(exponent))\n",
    "\n",
    "# This is the gradient of the logistic loss\n",
    "# The gradient is a vector that indicates the rate of change of the loss in each direction\n",
    "def gradient(theta, xi, yi):\n",
    "    exponent = yi * (xi.dot(theta))\n",
    "    return - (yi*xi) / (1+np.exp(exponent))\n",
    "\n",
    "def avg_grad(theta, X, y):\n",
    "    grads = [gradient(theta, xi, yi) for xi, yi in zip(X, y)]\n",
    "    return np.mean(grads, axis=0)\n",
    "\n",
    "# Prediction: take a model (theta) and a single example (xi) and return its predicted label\n",
    "def predict(xi, theta, bias=0):\n",
    "    label = np.sign(xi @ theta + bias)\n",
    "    return label\n",
    "\n",
    "def accuracy(theta):\n",
    "    return np.sum(predict(X_test, theta) == y_test)/X_test.shape[0]\n",
    "\n",
    "# L2 Clipping\n",
    "def L2_clip(v, b):\n",
    "    norm = np.linalg.norm(v, ord=2)\n",
    "    \n",
    "    if norm > b:\n",
    "        return b * (v / norm)\n",
    "    else:\n",
    "        return v\n",
    "    \n",
    "# Noisy gradient descent\n",
    "# Satisfies (k*epsilon, k*delta)-differential privacy\n",
    "def noisy_gradient_descent(iterations, epsilon, delta):\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    b = 3\n",
    "\n",
    "    for i in range(iterations):\n",
    "        gradients = [gradient(theta, x_i, y_i) for x_i, y_i in zip(X_train, y_train)]\n",
    "        clipped_gradient = np.mean([L2_clip(g, b) for g in gradients], axis=0)\n",
    "        noisy_gradient = gaussian_mech_vec(clipped_gradient, b/len(X_train), epsilon, delta)\n",
    "        theta = theta - noisy_gradient\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (20 points)\n",
    "\n",
    "Implement `noisy_gradient_descent_RDP`, a variant of noisy gradient descent that uses RÃ©nyi differential privacy. Your solution should have a **total** privacy cost of $(\\alpha, \\bar\\epsilon)$-RDP.\n",
    "\n",
    "See [Chapter 8](https://uvm-plaid.github.io/programming-dp/notebooks/ch8.html#renyi-differential-privacy) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc32b59df216c087bf2e33e108df4317",
     "grade": false,
     "grade_id": "cell-226ebaadc7eca7a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_mech_RDP_vec(vec, sensitivity, alpha, epsilon):\n",
    "    sigma = np.sqrt((sensitivity**2 * alpha) / (2 * epsilon))\n",
    "    return [v + np.random.normal(loc=0, scale=sigma) for v in vec]\n",
    "\n",
    "def noisy_gradient_descent_RDP(iterations, alpha, epsilon_bar):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "theta = noisy_gradient_descent_RDP(10, 20, 0.1)\n",
    "print('Final accuracy:', accuracy(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "713a575d16c6fbf1a50940131c567ee4",
     "grade": true,
     "grade_id": "cell-abdbebcaa40aa5f7",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "\n",
    "assert accuracy(noisy_gradient_descent_RDP(5, 100, 0.0001)) > 0.70\n",
    "assert accuracy(noisy_gradient_descent_RDP(5, 100, 0.00000001)) < 0.70\n",
    "assert accuracy(noisy_gradient_descent_RDP(5, 10000, 0.0001)) < 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (20 points)\n",
    "\n",
    "Implement `noisy_gradient_descent_zCDP`, a variant of noisy gradient descent that uses zero-concentrated differential privacy. Your solution should have a **total** privacy cost of $\\rho$-zCDP.\n",
    "\n",
    "See [Chapter 8](https://uvm-plaid.github.io/programming-dp/notebooks/ch8.html#zero-concentrated-differential-privacy) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e37a0c57cb9dab91430cef6b3bff5894",
     "grade": false,
     "grade_id": "cell-4f06568475493433",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_mech_zCDP_vec(vec, sensitivity, rho):\n",
    "    sigma = np.sqrt((sensitivity**2) / (2 * rho))\n",
    "    return [v + np.random.normal(loc=0, scale=sigma) for v in vec]\n",
    "\n",
    "def noisy_gradient_descent_zCDP(iterations, rho):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "theta = noisy_gradient_descent_zCDP(10, 0.1)\n",
    "print('Final accuracy:', accuracy(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c67f40613426a5105d6bfda862d13b8a",
     "grade": true,
     "grade_id": "cell-ccaeb1e7f69323a0",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "\n",
    "assert accuracy(noisy_gradient_descent_zCDP(5, 0.0000000001)) < 0.70\n",
    "assert accuracy(noisy_gradient_descent_zCDP(5, 0.0001)) > 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (10 points)\n",
    "\n",
    "Which of the following functions is likely to produce the best accuracy for a given privacy cost, and why? Which is likely to produce the worst accuracy for a given privacy cost, and why?\n",
    "\n",
    "- `noisy_gradient_descent`\n",
    "- `noisy_gradient_descent_RDP`\n",
    "- `noisy_gradient_descent_zCDP`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c683ec35c03829bf404f586e16c9c09",
     "grade": true,
     "grade_id": "cell-ad66d2db62678537",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 points)\n",
    "\n",
    "Implement `noisy_gradient_descent_zCDP_ED`, which has a **total privacy cost** of $(\\epsilon, \\delta)$-differential privacy, but which uses **zero-concentrated differential privacy** to perform composition.\n",
    "\n",
    "*Hint*: One approach is to:\n",
    "1. Convert $\\epsilon$ and $\\delta$ into an equivalent $\\rho$ parameter for zCDP\n",
    "2. Call `noisy_gradient_descent_zCDP` with the $\\rho$ from (1)\n",
    "\n",
    "See [Chapter 8](https://uvm-plaid.github.io/programming-dp/notebooks/ch8.html#zero-concentrated-differential-privacy) for more information on converting between variants. You will need to *approximate $\\rho$ computationally*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b90a11148243a4cace0f996c91ee7ab",
     "grade": false,
     "grade_id": "cell-22c62835056276a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def noisy_gradient_descent_zCDP_ED(iterations, epsilon, delta):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "theta = noisy_gradient_descent_zCDP_ED(10, 1.0, 1e-5)\n",
    "print('Final accuracy:', accuracy(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4455326a5b365fec966009f083cf68c4",
     "grade": true,
     "grade_id": "cell-26fab81b5bff9fc2",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "\n",
    "assert accuracy(noisy_gradient_descent_zCDP_ED(5, 0.1, 1e-5)) > 0.70\n",
    "assert accuracy(noisy_gradient_descent_zCDP_ED(5, 1.0, 1e-5)) > 0.70"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
