{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CS211: Data Privacy\n",
    "## In-Class Exercise, week of 10/31/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def gaussian_mech_vec(vec, sensitivity, epsilon, delta):\n",
    "    return [v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "            for v in vec]\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "# adult = pd.read_csv('https://github.com/jnear/cs211-data-privacy/raw/master/homework/adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data files\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "url_x = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_x.npy'\n",
    "url_y = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_y.npy'\n",
    "\n",
    "with urllib.request.urlopen(url_x) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "X = np.load(f)\n",
    "\n",
    "with urllib.request.urlopen(url_y) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test set sizes: 36176 9044\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "training_size = int(X.shape[0] * 0.8)\n",
    "\n",
    "X_train = X[:training_size]\n",
    "X_test = X[training_size:]\n",
    "\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "print('Train and test set sizes:', len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 1\n",
    "\n",
    "Using scikit-learn, train a logistic regression model on the training data loaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6eeb7ec9241a2a7c54c5594dc4d77c69",
     "grade": true,
     "grade_id": "cell-32c8bf5cd1ba5719",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients: [ 7.12843459e-01  4.03115227e-02  2.03668555e-01  3.03399365e-01\n",
      " -3.49085623e-01 -1.30264647e-01 -7.89046462e-01 -4.84280257e-01\n",
      " -4.83121335e-01 -3.52070934e-01 -4.82226146e-01 -1.16623517e-01\n",
      " -5.10892351e-01 -6.09961426e-01  9.39198361e-02  1.72695409e-01\n",
      "  5.11946054e-01  9.36487398e-01 -1.12024921e-02  7.19784481e-01\n",
      " -7.99418435e-01  1.21953621e+00  1.87253680e-01 -6.53540142e-01\n",
      "  1.71197926e+00  1.51818448e+00 -3.53658922e-01 -1.06503147e+00\n",
      " -6.51703018e-01 -5.14404018e-01  8.32844519e-02  1.21773688e-01\n",
      "  1.39520033e-01  8.59699325e-01 -7.61815650e-01 -5.55754524e-01\n",
      " -1.84741033e-01 -7.96587410e-01 -1.14160664e+00  6.10503587e-01\n",
      "  6.12135081e-01  3.58268868e-01  6.44688013e-01  2.45838356e-03\n",
      " -1.06008120e-01  2.92462169e-01 -4.97695367e-01 -7.68881226e-01\n",
      "  9.38140594e-02  9.78134655e-01 -1.93782726e-01  3.17945118e-01\n",
      " -1.54762640e-01 -8.20262822e-02  1.04452701e-01 -3.38610379e-01\n",
      "  3.30436550e-01  9.40924414e-01  6.66686212e-01 -2.40896748e-01\n",
      " -1.26802026e+00  2.24155171e-01 -5.53073908e-01 -2.42562664e-01\n",
      " -2.05110071e-01  7.33062517e-01  9.42864428e-01  7.85115864e-02\n",
      "  1.52346232e-01  4.81901477e-02  3.81079359e-01 -2.07699091e-02\n",
      "  1.00089794e-01 -1.93156932e-01  5.39259435e-01  3.29582422e-02\n",
      "  3.30547583e-01  7.50438903e-01  8.67226821e-01  3.43654231e-01\n",
      " -3.24808655e-02 -6.14447250e-01 -4.41191340e-01 -3.37678946e-01\n",
      " -2.97751512e-01 -5.70914236e-01  3.18724372e-01  5.95801319e-02\n",
      "  3.86061015e-01 -1.12312588e-01 -8.35222952e-01 -7.30094732e-01\n",
      " -9.73139252e-02 -5.31223694e-01 -4.20779501e-01  3.65394179e-01\n",
      " -9.46723330e-01  4.21796763e-01  2.28617419e+00  9.83287701e-01\n",
      "  2.40601929e+00  1.86837975e+01  2.61564318e+00  2.75885803e+00]\n",
      "Model accuracy: 0.8448695267580717\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    return LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "model = train_model()\n",
    "print('Model coefficients:', model.coef_[0])\n",
    "print('Model accuracy:', np.sum(model.predict(X_test) == y_test)/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "Implement the *average gradient* of the loss below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The loss function measures how good our model is. The training goal is to minimize the loss.\n",
    "# This is the logistic loss function.\n",
    "def loss(theta, xi, yi):\n",
    "    exponent = - yi * (xi.dot(theta))\n",
    "    return np.log(1 + np.exp(exponent))\n",
    "\n",
    "# This is the gradient of the logistic loss\n",
    "# The gradient is a vector that indicates the rate of change of the loss in each direction\n",
    "def gradient(theta, xi, yi):\n",
    "    exponent = yi * (xi.dot(theta))\n",
    "    return - (yi*xi) / (1+np.exp(exponent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab7d67d24660b6cbf040bc661971aaa0",
     "grade": true,
     "grade_id": "cell-ace29743234ed3f6",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def avg_grad(theta, X, y):\n",
    "    return np.mean([gradient(theta, xi, yi) for xi, yi in zip(X, y)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 3\n",
    "\n",
    "Use the average gradient from above to implement a gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4850cab1fb79077d710818b58adf4fc",
     "grade": true,
     "grade_id": "cell-87483deb56e7ce88",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1.63933476e-02, -2.62737908e-02, -3.76703876e-01,  5.75414219e-02,\n       -6.45755008e-02, -2.73486282e-02, -1.30672661e-03, -5.91543132e-02,\n       -7.64880798e-02, -2.62061378e-02, -1.57561761e-02, -2.86662073e-02,\n       -4.72301785e-02, -3.76260473e-02, -9.90166218e-03, -1.97245917e-02,\n        1.55177596e-01,  4.49929106e-02, -3.29796604e-01,  1.19518106e-01,\n       -4.89454322e-03,  6.88790663e-02, -1.55396891e-01, -1.80599005e-01,\n        1.54260151e-03,  3.89119966e-01, -1.97894731e-02, -5.15748994e-01,\n       -5.58626968e-02, -4.09361505e-02, -1.28065226e-01, -1.62203385e-04,\n       -1.08119029e-01,  1.88498244e-01, -6.47481586e-02, -8.66006277e-02,\n       -9.99400278e-02, -2.05565204e-01, -1.11388992e-02,  1.61706332e-01,\n       -3.59862313e-03, -1.50012146e-02,  1.68869178e-03, -5.12278071e-02,\n        3.20211424e-01, -2.99730645e-01, -6.21807885e-02, -2.79987375e-01,\n       -1.81265739e-01,  8.06793703e-02, -1.62147320e-02, -2.28589562e-02,\n       -1.37829430e-01, -1.60678844e-02, -2.29302751e-01, -3.66995428e-01,\n       -5.52783255e-02,  1.71465403e-04,  1.01657252e-03, -2.30554477e-03,\n       -4.49929315e-03, -3.16006935e-03, -5.97944101e-03, -2.17232333e-03,\n       -6.49185240e-03,  2.25224908e-03,  1.03307811e-03, -2.97354842e-03,\n        4.61969711e-06, -4.47281179e-03, -2.64817559e-03, -6.27231883e-05,\n       -8.45045871e-04, -5.36070827e-04,  9.85204107e-05,  8.18802416e-04,\n        2.81426612e-04, -1.10188120e-04, -3.16311117e-04, -4.14059871e-03,\n       -2.56618731e-04, -1.23603629e-03, -5.52492747e-02, -2.68278922e-03,\n       -1.13850454e-03, -2.58782610e-03, -4.19239246e-03, -2.31953654e-03,\n       -2.62620550e-03, -8.63337753e-03, -1.04120760e-03, -4.43136447e-03,\n        2.32630683e-04, -1.21364005e-03, -1.63560801e-03, -2.93003921e-01,\n       -5.03114545e-03, -1.89672372e-04, -7.59047983e-02, -5.58277360e-02,\n       -6.33588757e-02,  5.91506903e-02,  4.41760150e-02, -8.32223096e-02])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_descent(iterations):\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    eta = 1\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        theta = theta - eta * avg_grad(theta, X_train, y_train)\n",
    "\n",
    "    return theta\n",
    "\n",
    "theta = gradient_descent(10)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.7787483414418399"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction: take a model (theta) and a single example (xi) and return its predicted label\n",
    "def predict(xi, theta, bias=0):\n",
    "    label = np.sign(xi @ theta + bias)\n",
    "    return label\n",
    "\n",
    "def accuracy(theta):\n",
    "    return np.sum(predict(X_test, theta) == y_test)/X_test.shape[0]\n",
    "\n",
    "accuracy(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 4\n",
    "\n",
    "Implement a *noisy gradient descent* algorithm.\n",
    "\n",
    "1. Calculate gradients for each example\n",
    "2. Clip the gradients to have bounded $L2$ norm\n",
    "3. Sum the clipped gradients\n",
    "4. Use the Gaussian mechanism to add noise to the sum of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08fb7218fda03e851c308317aac647b0",
     "grade": false,
     "grade_id": "cell-0b1fc630cdb8484b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.5553958425475454\n"
     ]
    }
   ],
   "source": [
    "def L2_clip(v, b):\n",
    "    norm = np.linalg.norm(v, ord=2)\n",
    "    \n",
    "    if norm > b:\n",
    "        return b * (v / norm)\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def noisy_gradient_descent(iterations, epsilon, delta):\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    eta = 1\n",
    "    b = 3 # L2 clipping param\n",
    "\n",
    "\n",
    "    # seq comp\n",
    "    epsilon_count = .1 * epsilon\n",
    "    epsilon_loop = epsilon - epsilon_count\n",
    "    epsilon_i = epsilon_loop / iterations\n",
    "    delta_i = delta / iterations\n",
    "\n",
    "    noisy_count = laplace_mech(len(X_train), 1, epsilon_count)\n",
    "    for _ in range(iterations):\n",
    "        grads = [gradient(theta, x, y) for x, y in zip(X_train, y_train)]\n",
    "        clipped_grads = [L2_clip(g, b) for g in grads]\n",
    "        grad_sum = np.sum(clipped_grads, axis=0)\n",
    "\n",
    "        noisy_grad_sum = gaussian_mech_vec(grad_sum, b, epsilon_i, delta_i)\n",
    "        noisy_grad_avg = np.array(noisy_grad_sum) / noisy_count\n",
    "        theta = theta - eta * noisy_grad_avg\n",
    "\n",
    "    return theta\n",
    "\n",
    "theta = noisy_gradient_descent(10, 0.001, 1e-5)\n",
    "print('Final accuracy:', accuracy(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd498649d6383404040839a1ac75d0c4",
     "grade": true,
     "grade_id": "cell-abdbebcaa40aa5f7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "\n",
    "assert accuracy(noisy_gradient_descent(5, 0.001, 1e-5)) < 0.76\n",
    "assert accuracy(noisy_gradient_descent(5, 1.0, 1e-5)) > 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 5\n",
    "\n",
    "What is the *total privacy cost* of the noisy gradient descent algorithm above, and why? Argue informally that the algorithm satisfies this privacy cost. Use sequential composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01db8df655fd88392405c730527f3e64",
     "grade": true,
     "grade_id": "cell-ba58f3f4ee199481",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The privacy cost outside the loop is:\n",
    " laplace for count has sens 1,\n",
    " total cost is epsilon\n",
    "The total privacy cost per iteration is\n",
    "sensitivity: gaussian for sum of vectors with l2 norm <= b, sens b\n",
    "composition: total cost is (epsilon, delta)\n",
    "post-processing: theta is updated only with diff private info\n",
    "\n",
    "total priv cost:\n",
    "10 iterations\n",
    "by sequential composition, total cost = (11 * epsilon, 10 * delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 6\n",
    "\n",
    "Repeat the above, but using advanced composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec1e540eb29decdc214d46eeb15c6da1",
     "grade": true,
     "grade_id": "cell-c9effbc5db1e2de3",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Outside the loop: (epsilon, 0)\n",
    "Inside the loop: (epsilon, delta) per iter\n",
    "\n",
    "use adv comp for loop, then seq comp to combine with outside loop\n",
    "```\n",
    "delta' = delta = 1e-5\n",
    "epsilon' = 2 * epsilon * sqrt(2 * k * log(1/delta'))\n",
    "= 2 * 1 * sqrt(2 * 10 * log(1/1e-5)\n",
    "= 30.34\n",
    "final epsilon = epsilon' + epsilon 30.34 + 1\n",
    "final delta = k * delta + delta' = 10 * 1e5 + 1e5 = 0.00011\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 7\n",
    "\n",
    "Implement a version of noisy gradient descent that satisfies a *total* of $(\\epsilon, \\delta)$-differential privacy. Use sequential composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f395037ed06f9bc220e8413ebb6f6c88",
     "grade": false,
     "grade_id": "cell-a4171a5ddcc6c2b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "\n",
    "assert accuracy(noisy_gradient_descent(5, 0.001, 1e-5)) < 0.76\n",
    "assert accuracy(noisy_gradient_descent(5, 1.0, 1e-5)) > 0.70"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}